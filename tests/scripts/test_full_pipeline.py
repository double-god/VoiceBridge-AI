"""
å®Œæ•´æµç¨‹æµ‹è¯•: ASR â†’ LLM â†’ TTS
æµ‹è¯•ä½¿ç”¨ demo æ•°æ®ä¸­çš„ Anita æ¡ˆä¾‹

âš ï¸ æ­¤è„šæœ¬éœ€è¦åœ¨ AI Agent å®¹å™¨å†…è¿è¡Œ
è¿è¡Œæ–¹æ³•:
  docker exec -it voicebridge_ai_agent python3 /app/tests/scripts/test_full_pipeline.py
"""

import asyncio
import sys
import os
import json

# æ£€æµ‹è¿è¡ŒçŽ¯å¢ƒ
if os.path.exists("/app/core"):
    # åœ¨å®¹å™¨å†…
    sys.path.insert(0, "/app")
else:
    # åœ¨å®¿ä¸»æœºï¼Œä¸æ”¯æŒç›´æŽ¥è¿è¡Œ
    print("âŒ é”™è¯¯: æ­¤è„šæœ¬éœ€è¦åœ¨ Docker å®¹å™¨å†…è¿è¡Œ")
    print("")
    print("è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤:")
    print(
        "  docker exec -it voicebridge_ai_agent python3 tests/scripts/test_full_pipeline.py"
    )
    print("")
    print("æˆ–è€…ä½¿ç”¨ HTTP API æµ‹è¯•è„šæœ¬:")
    print("  python3 tests/scripts/test_asr_llm.py")
    print("  python3 tests/scripts/test_upload_quick.py")
    sys.exit(1)

from core.asr_whisper import transcribe
from core.llm_reasoning import infer_intent
from core.tts_cosy import tts_edge


async def test_full_pipeline(sample_name="Anita"):
    """
    æµ‹è¯•å®Œæ•´çš„è¯­éŸ³å¤„ç†æµç¨‹

    Args:
        sample_name: æµ‹è¯•æ ·æœ¬åç§° (Anita, JAMES, ROSE)
    """
    print("=" * 60)
    print("ðŸ§ª å®Œæ•´æµç¨‹æµ‹è¯•: ASR â†’ LLM â†’ TTS")
    print("=" * 60)

    # æ•°æ®è·¯å¾„ï¼ˆå®¹å™¨å†…è·¯å¾„ï¼‰
    json_file = f"/app/data/demo/{sample_name}.json"
    audio_file = f"/app/data/demo/{sample_name}.wav"

    # æ£€æŸ¥æ–‡ä»¶
    if not os.path.exists(json_file):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
        return
    if not os.path.exists(audio_path):
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        return

    # è¯»å–ç”¨æˆ·æ¡£æ¡ˆ
    with open(json_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    profile = data["metadata"]["patient_profile"]

    print(f"\nðŸ“ æµ‹è¯•æ•°æ®: {sample_name}")
    print(f'ðŸ‘¤ ç”¨æˆ·: {profile["name"]}, {profile["age"]}å²')
    print(f'ðŸ“ çŠ¶å†µ: {profile["condition"]}')
    print(f"ðŸŽµ éŸ³é¢‘: {audio_path}")

    # Step 1: ASR (è¯­éŸ³è¯†åˆ«)

    print("\n" + "â”€" * 60)
    print("ðŸ“ Step 1: è¯­éŸ³è¯†åˆ« (ASR)")
    print("â”€" * 60)

    transcription = transcribe(audio_path)
    print(f"âœ… è¯†åˆ«ç»“æžœ ({len(transcription)} å­—ç¬¦):")
    print(f"   {transcription[:200]}...")

    # ============================================================
    # Step 2: LLM (æ„å›¾ç†è§£)
    # ============================================================
    print("\n" + "â”€" * 60)
    print("ðŸ§  Step 2: æ„å›¾ç†è§£ (LLM)")
    print("â”€" * 60)

    user_profile = {
        "name": profile["name"],
        "age": profile["age"],
        "condition": profile["condition"],
        "habits": profile.get("habits", ""),
        "common_needs": profile.get("common_needs", []),
    }

    intent_result = infer_intent(transcription, user_profile)

    print(f"âœ… æ„å›¾åˆ†æž:")
    print(f'   å†³ç­–: {intent_result["decision"]}')
    print(f'   ç½®ä¿¡åº¦: {intent_result["confidence"]}')
    print(f'   åŽŸå› : {intent_result["reason"][:100]}...')
    print(f'   ç²¾ç‚¼æ–‡æœ¬: {intent_result["refined_text"][:150]}...')

    # ============================================================
    # Step 3: TTS (è¯­éŸ³åˆæˆ)
    # ============================================================
    print("\n" + "â”€" * 60)
    print("ðŸ”Š Step 3: è¯­éŸ³åˆæˆ (TTS)")
    print("â”€" * 60)

    # ä½¿ç”¨ç²¾ç‚¼åŽçš„æ–‡æœ¬å‰80å­—ä½œä¸ºå“åº”
    response_text = intent_result["refined_text"][:80] + "..."
    print(f"ðŸ“¢ å¾…åˆæˆæ–‡æœ¬: {response_text}")

    # ä¿å­˜åˆ° output ç›®å½•ï¼ˆæŒ‚è½½åˆ°å®¿ä¸»æœºï¼‰
    output_dir = "/app/output"
    os.makedirs(output_dir, exist_ok=True)

    output_path = await tts_edge(response_text, output_dir)
    file_size = os.path.getsize(output_path) / 1024

    # è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„æ˜¾ç¤º
    relative_path = output_path.replace("/app/", "")
    print(f"âœ… è¯­éŸ³åˆæˆå®Œæˆ: {relative_path} ({file_size:.1f} KB)")

    # ============================================================
    # æµ‹è¯•æ€»ç»“
    # ============================================================
    print("\n" + "=" * 60)
    print("ðŸŽ‰ å®Œæ•´æµç¨‹æµ‹è¯•æˆåŠŸï¼")
    print("   ASR: Whisper (base) âœ“")
    print("   LLM: DashScope qwen-max âœ“")
    print("   TTS: CosyVoice-300M-SFT âœ“")
    print("=" * 60)
    print(f"\nðŸ’¾ ç”Ÿæˆçš„è¯­éŸ³æ–‡ä»¶: {output_path}")


if __name__ == "__main__":
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°æŒ‡å®šæµ‹è¯•æ ·æœ¬
    sample = sys.argv[1] if len(sys.argv) > 1 else "Anita"
    asyncio.run(test_full_pipeline(sample))
